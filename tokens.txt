is
a
for
out
of
and
it
with
your
to
of
and
the
it
or
of
these
all
of
with
i
you
what
the
is
for
how
it
how
to
it
how
to
it
do
what
you
and
what
to
do
when
it
your
the
in
this
should
the
same
in
and
you
be
for
the
for
if
so
you
should
that
is
no
being
and
that
is
for
all
if
you
to
about
the
between
and
to
this
has
been
into
other
by
if
you
have
about
or
into
to
the
if
your
an
be
to
what
the
about
that
an
be
as
an
this
its
of
a
from
in
the
through
a
which
the
as
a
here
are
some
to
that
is
all
the
a
a
is
all
the
from
a
does
this
what
you
if
so
on
if
a
of
or
you
with
the
for
for
is
through
so
if
you
it
with
the
you
it
with
or
the
is
and
the
same
on
and
you
the
of
or
for
your
these
be
and
if
the
is
not
what
you
the
of
so
its
but
if
you
should
if
you
have
or
you
the
and
it
with
if
all
the
for
you
to
the
with
your
you
the
its
into
your
and
it
at
all
i
and
to
but
it
should
with
other
after
is
as
when
you
it
for
with
its
to
if
you
the
the
be
there
have
been
on
of
the
being
if
you
the
no
your
is
that
the
of
the
under
if
you
the
no
your
is
that
the
of
the
under
in
both
your
is
to
the
from
your
any
when
you
the
and
the
again
if
you
the
on
the
you
to
the
to
you
do
this
by
the
or
by
to
on
the
to
a
the
in
but
it
a
of
is
the
on
your
you
with
of
these
is
the
which
the
a
does
on
your
you
with
of
these
this
the
and
of
each
if
you
i
you
and
for
if
a
of
than
or
a
of
than
its
that
you
or
in
is
not
very
in
that
if
a
is
for
it
between
for
the
to
a
it
into
the
you
in
a
or
an
the
is
to
and
are
to
then
the
the
it
an
you
it
to
an
of
a
into
a
of
but
only
have
to
with
about
of
and
a
to
an
or
in
the
have
a
of
and
and
most
of
them
in
the
and
the
for
the
most
of
a
are
its
and
has
a
as
if
you
a
the
be
in
any
by
a
have
any
of
the
has
an
is
you
a
by
the
a
you
that
as
you
and
a
again
this
is
by
the
as
a
a
few
that
have
a
of
them
but
a
few
more
the
most
is
that
is
a
have
more
than
and
the
of
a
as
a
if
an
it
has
more
than
but
its
not
a
as
by
any
of
the
the
when
you
a
into
a
are
you
this
by
as
a
into
the
you
to
a
a
or
not
its
a
if
you
a
as
there
are
no
again
you
this
the
you
to
do
this
but
if
you
do
the
as
a
they
the
in
the
a
to
a
of
a
the
to
these
of
a
is
a
that
it
some
of
the
in
the
and
the
you
a
to
a
with
you
a
in
but
you
with
most
of
the
in
the
and
the
but
not
all
of
them
in
a
the
a
a
or
the
or
or
the
if
you
to
a
of
you
should
on
it
to
it
into
a
if
you
your
a
to
the
when
this
is
a
of
the
itself
the
as
a
for
most
you
it
as
a
this
it
most
of
the
in
the
and
the
the
to
an
or
it
has
no
and
no
but
its
to
at
its
so
its
been
the
and
other
and
in
an
or
but
there
are
a
few
the
only
to
about
is
the
the
is
a
of
but
when
it
as
of
an
a
is
with
for
that
up
in
an
and
these
are
of
that
to
the
an
that
the
with
a
the
the
again
this
as
an
to
you
how
to
from
of
a
to
down
and
other
these
are
the
a
of
for
and
over
a
that
any
of
these
because
a
have
the
to
the
is
to
the
of
the
you
if
you
the
you
do
this
again
and
again
to
in
on
a
of
the
this
the
the
a
as
an
you
only
the
by
that
if
you
to
all
the
a
or
more
than
the
with
a
to
of
the
in
the
such
as
and
a
are
in
a
the
itself
has
in
this
the
is
the
of
the
a
does
not
have
because
it
of
them
as
a
you
over
a
the
the
and
only
a
for
the
has
a
but
the
itself
has
a
the
the
a
in
which
that
is
a
of
the
the
you
over
all
of
a
its
the
of
its
and
so
on
the
has
only
but
it
has
the
and
the
the
only
has
the
but
it
has
a
of
if
a
has
only
and
that
is
a
the
is
as
if
a
only
is
and
that
has
a
then
the
is
to
have
the
same
as
its
if
a
more
than
then
its
not
what
should
to
so
is
to
be
and
if
more
than
a
you
at
the
the
these
to
have
a
of
which
you
by
the
here
of
are
and
at
the
and
of
is
up
the
and
has
a
the
that
it
you
an
with
the
in
the
the
is
the
of
the
the
itself
has
a
the
that
it
the
of
a
is
the
itself
and
the
of
a
is
as
you
over
all
of
an
with
this
to
from
an
a
the
to
the
very
of
the
a
this
the
and
the
are
at
the
same
both
of
the
same
we
them
when
a
is
up
at
the
same
you
this
in
the
you
and
you
and
to
between
that
are
on
the
same
of
the
the
has
a
but
no
because
before
the
on
the
same
of
the
for
the
same
the
has
a
but
no
the
and
are
not
because
they
have
the
same
in
the
or
of
a
be
a
to
the
you
that
the
of
the
a
would
be
the
a
but
its
a
the
and
that
the
a
from
the
the
a
is
the
of
the
and
you
over
a
with
or
and
a
at
the
of
the
an
this
of
and
it
into
a
of
an
a
a
a
the
a
and
so
on
for
the
of
the
and
the
of
a
or
to
was
it
be
the
same
as
but
its
the
a
in
the
its
is
a
the
of
the
that
was
by
the
of
the
a
but
the
of
that
a
the
that
was
after
the
a
is
not
the
of
that
its
the
because
in
the
the
before
that
the
an
a
then
the
then
the
a
then
the
and
of
the
the
is
on
the
same
as
the
a
but
the
was
the
is
the
of
it
to
was
before
this
and
you
should
the
by
you
these
to
or
in
the
as
it
was
the
a
of
for
the
but
all
very
to
a
of
the
most
and
the
other
the
same
so
them
once
again
be
the
as
an
by
in
a
to
an
you
in
on
the
of
the
in
of
before
in
about
and
i
to
of
you
into
these
these
up
again
and
again
the
you
them
to
on
a
on
its
on
the
of
a
or
on
some
of
these
a
the
is
a
a
to
a
and
a
against
that
this
all
the
in
the
if
you
in
a
the
is
as
you
this
by
in
a
a
if
you
in
a
against
that
its
this
all
the
with
the
in
this
the
and
the
this
all
the
the
a
if
you
in
a
a
against
any
in
that
this
all
the
a
and
all
the
the
it
this
all
the
in
the
but
of
the
a
if
of
the
other
for
you
a
that
an
as
its
only
the
should
if
the
and
a
that
if
a
the
but
the
this
into
and
up
all
the
this
only
up
the
it
up
the
a
because
those
both
and
it
up
and
because
those
if
you
in
a
to
on
a
the
into
the
be
the
not
the
a
that
all
a
does
not
a
the
be
as
as
you
it
to
be
a
that
if
a
is
by
were
to
at
the
in
the
through
a
and
all
that
your
i
in
of
but
here
are
a
few
more
some
of
these
should
but
are
what
does
it
to
in
a
for
or
why
does
a
with
the
at
the
to
the
in
a
for
and
to
only
with
be
as
that
this
is
the
from
of
that
the
to
be
a
a
a
a
or
the
the
any
not
be
into
a
on
of
a
if
you
in
a
for
an
against
each
if
you
in
a
for
against
each
you
an
on
a
a
a
a
or
the
this
all
has
a
of
what
the
is
you
at
once
by
in
more
than
some
the
in
have
that
be
as
the
of
you
these
in
by
them
into
a
and
the
into
as
the
you
a
to
for
because
the
to
the
of
the
itself
you
a
to
in
the
by
its
very
to
for
a
that
has
a
but
the
of
the
is
a
in
as
a
you
a
as
of
you
by
the
as
with
any
you
a
a
a
or
that
a
have
for
its
when
you
for
a
that
a
against
any
of
its
you
for
the
of
the
but
for
of
the
if
you
to
for
that
or
more
you
should
a
in
of
which
have
the
you
the
above
a
for
is
the
or
or
you
to
for
the
with
you
for
of
as
with
and
the
you
in
a
a
a
a
or
the
here
are
some
is
for
you
it
with
that
all
your
for
this
the
a
is
the
is
in
in
it
was
the
all
the
and
that
your
this
a
while
if
the
is
if
you
all
the
you
in
a
for
this
the
in
it
to
after
its
a
there
are
in
the
but
this
only
the
the
if
you
all
the
of
its
its
and
so
on
if
you
only
to
you
in
the
here
that
of
the
the
is
the
but
its
not
the
the
is
in
the
the
when
its
to
at
all
of
the
but
when
it
to
the
it
a
of
below
and
they
the
same
as
and
the
but
the
is
and
are
the
only
that
it
into
a
be
very
a
is
because
is
the
most
in
the
you
a
for
it
if
you
the
or
a
as
it
were
a
then
its
the
same
as
on
that
these
of
are
these
are
the
the
for
but
you
only
to
if
you
a
only
has
its
a
of
to
the
for
more
than
in
you
you
the
these
of
are
the
only
is
that
a
the
and
the
if
it
an
if
it
the
from
that
by
and
i
a
of
above
and
the
other
for
the
but
be
of
these
are
the
same
as
and
the
other
are
the
same
as
the
only
are
in
what
of
the
they
and
that
and
their
down
the
at
these
do
the
they
their
up
the
at
a
or
a
them
out
from
a
in
the
of
the
a
is
the
of
the
in
so
our
it
of
the
is
an
of
the
and
our
that
as
a
with
the
in
the
but
its
not
of
this
so
we
it
with
you
have
the
between
and
and
the
and
the
is
very
these
to
over
all
the
and
each
against
the
to
if
it
and
these
to
over
the
of
an
in
the
the
all
the
that
and
only
the
and
these
to
over
an
that
it
in
the
the
all
the
that
and
only
the
and
these
to
over
and
that
after
it
in
the
the
all
and
only
the
in
the
the
up
it
was
the
a
we
from
in
the
the
in
the
up
its
not
in
the
same
of
the
as
the
a
we
from
for
these
all
that
is
that
an
the
and
up
in
the
than
the
and
these
to
over
the
and
that
before
it
in
the
the
all
and
only
the
the
to
the
in
the
the
with
but
it
the
the
that
the
a
we
with
this
be
too
were
at
all
the
that
up
in
the
than
the
we
with
a
that
an
a
have
up
before
the
a
it
as
of
most
the
if
you
through
was
at
the
same
so
you
have
to
do
has
a
which
to
a
against
a
and
all
the
has
a
which
a
against
the
of
a
of
have
the
but
only
the
most
are
the
all
the
but
here
are
some
of
the
you
other
other
the
of
by
by
that
any
from
a
of
for
the
of
an
by
a
which
only
the
that
a
if
that
you
them
in
when
a
that
the
it
when
the
you
this
by
in
your
own
of
all
this
is
a
for
who
the
you
do
all
of
this
with
the
and
if
are
all
you
you
should
the
with
its
a
but
this
you
with
the
the
is
in
the
but
you
the
and
your
as
a
or
and
i
this
in
but
it
you
a
the
of
its
and
if
you
a
the
are
with
the
you
be
if
the
other
they
and
all
their
be
you
to
a
with
it
on
a
in
a
which
on
a
and
if
you
to
a
to
a
no
a
in
to
or
you
the
if
you
to
a
or
some
other
of
the
this
is
a
in
what
if
you
to
a
the
is
to
the
only
the
the
is
is
the
at
the
of
its
be
at
you
it
on
a
and
the
or
before
in
the
the
or
in
the
the
of
a
a
or
from
the
it
the
or
that
was
at
this
you
have
at
the
you
to
the
and
at
the
that
was
you
on
to
on
a
of
the
you
a
from
the
then
it
and
its
a
or
from
the
and
it
with
the
or
of
your
the
or
that
was
so
that
you
it
or
it
to
of
the
an
in
the
you
it
the
this
is
in
is
the
of
it
a
with
that
its
for
out
the
that
was
after
a
of
that
the
you
up
with
or
more
to
each
other
have
any
with
this
but
it
in
a
you
not
the
you
to
up
the
by
the
is
in
the
a
into
a
with
a
for
each
and
each
you
on
the
or
on
any
of
its
if
you
a
with
no
you
or
on
a
or
a
it
the
a
in
for
other
you
to
a
and
to
if
you
a
that
be
to
if
you
then
the
to
a
the
be
as
you
the
by
the
only
that
are
are
and
these
into
and
so
that
or
you
this
by
a
for
the
to
or
for
the
is
only
be
to
that
if
you
in
to
if
you
in
its
the
same
as
but
the
in
if
you
in
not
at
all
on
this
is
the
but
it
to
as
in
these
if
you
more
over
your
you
a
that
to
they
in
a
or
in
an
or
you
more
over
the
for
the
in
by
to
this
off
you
the
which
which
are
and
in
what
this
out
the
it
if
you
a
the
that
is
as
it
with
no
the
in
a
that
all
the
in
the
or
but
it
the
if
you
only
the
of
a
or
you
the
it
all
the
in
a
or
a
as
a
you
a
to
be
to
the
of
you
to
from
the
and
of
each
of
but
at
that
you
to
the
and
the
yourself
the
to
if
you
to
some
you
the
into
the
and
be
a
for
you
and
the
but
there
are
a
few
you
in
to
the
to
which
is
the
to
the
is
a
or
an
you
the
is
how
the
if
you
the
as
being
the
then
then
in
you
this
by
of
the
the
a
the
if
you
have
an
your
and
a
the
only
is
if
you
have
for
an
you
and
for
between
the
same
to
a
of
but
each
is
from
the
same
the
are
between
the
and
the
a
as
an
is
not
the
it
into
a
the
same
as
this
that
you
have
that
the
is
and
that
the
is
an
of
being
into
an
there
are
between
if
you
a
these
be
than
but
all
you
a
that
the
but
if
the
is
not
a
that
the
is
the
same
of
the
it
with
an
this
an
to
the
the
same
with
in
this
the
this
no
to
a
by
a
it
to
an
the
is
of
these
is
the
to
it
the
that
are
of
the
so
it
has
the
on
being
the
but
all
are
between
your
if
on
your
to
other
or
it
on
you
should
a
in
the
that
the
that
your
a
from
the
you
it
any
or
is
in
a
or
but
when
you
that
into
its
been
to
its
not
that
would
be
a
to
a
and
it
to
the
is
as
the
of
the
most
of
the
but
it
it
but
only
after
a
by
of
the
that
a
very
if
you
to
a
of
you
and
by
it
to
the
as
a
in
the
is
so
that
a
on
it
and
it
as
we
this
by
in
the
if
you
what
the
is
but
you
that
is
you
the
in
as
but
that
is
a
of
so
its
is
a
in
in
when
a
in
a
the
only
to
be
to
some
with
the
if
to
do
this
it
the
to
on
the
or
this
you
that
the
is
not
an
of
the
was
if
a
but
is
that
the
was
there
as
it
is
in
this
and
in
for
when
you
out
a
from
you
a
if
the
in
to
with
a
in
the
that
the
has
been
to
the
that
the
is
in
if
you
you
an
into
you
on
the
or
any
in
the
as
if
it
were
a
any
that
be
in
your
be
into
a
that
the
the
be
of
a
it
but
no
for
that
in
or
so
its
into
for
those
you
its
you
have
in
an
and
you
it
to
a
more
if
you
the
or
the
more
you
the
more
it
if
you
have
your
own
as
to
what
the
be
you
them
in
as
a
has
that
you
to
to
or
you
to
this
but
it
the
which
is
to
to
with
a
is
in
but
such
as
again
this
when
a
from
you
to
such
a
into
a
this
is
a
the
are
in
and
the
are
in
you
the
or
the
but
not
both
the
as
a
and
it
as
you
the
to
you
to
it
to
and
the
and
only
how
to
in
or
i
but
this
is
the
most
that
you
to
on
your
before
it
into
or
the
that
a
has
a
it
be
if
you
it
a
that
both
and
its
to
the
is
and
the
out
i
is
in
for
that
or
are
when
they
the
same
or
in
this
the
are
as
they
in
of
the
because
they
both
if
you
to
to
the
same
is
you
to
a
of
any
or
the
is
to
the
it
the
same
as
the
but
its
not
the
same
the
only
is
that
the
is
from
the
as
if
had
been
on
it
this
is
because
the
same
at
the
same
only
of
a
you
to
at
a
a
its
a
of
and
to
the
and
then
over
it
again
for
a
it
would
be
to
that
an
a
in
the
the
you
to
which
of
an
are
you
a
and
it
in
to
the
as
the
that
this
if
the
if
you
the
be
no
what
this
is
because
the
as
it
and
if
some
of
the
it
into
the
to
in
the
below
be
to
in
the
the
same
as
a
from
the
and
here
are
to
the
more
and
what
the
when
its
with
these
you
a
into
any
of
the
in
the
this
but
i
it
if
having
what
does
to
a
the
into
the
in
out
a
you
how
the
and
you
if
a
that
could
be
at
the
of
you
how
to
the
if
not
you
the
of
when
for
when
a
there
are
of
there
are
where
you
a
to
and
it
an
an
and
there
is
where
a
a
than
the
to
it
of
these
out
to
be
with
this
is
not
because
is
an
of
its
because
any
it
on
if
on
a
the
is
to
a
a
for
and
a
the
most
are
and
these
are
both
by
in
and
the
is
to
or
the
most
of
is
that
you
a
that
you
is
in
the
you
it
in
but
or
this
is
with
in
which
it
again
the
is
to
or
by
as
to
a
as
in
as
the
to
the
to
have
other
be
as
as
the
it
on
of
if
is
if
for
by
the
or
if
any
other
why
is
more
than
you
should
about
and
that
there
are
you
do
to
up
if
not
as
the
my
is
to
than
or
you
up
by
the
only
of
a
you
the
but
it
a
of
and
the
is
the
and
is
no
being
its
with
all
its
through
as
you
a
of
if
you
or
but
your
you
by
you
to
the
for
is
to
most
against
against
with
all
you
should
have
to
do
is
the
from
to
so
this
this
is
with
most
of
its
have
been
and
for
there
are
other
and
and
a
few
of
them
what
to
to
your
and
to
you
a
a
that
was
and
in
by
but
you
in
or
and
that
a
for
a
is
not
the
same
as
you
that
you
a
than
for
the
same
if
you
out
for
or
you
that
the
again
if
this
to
your
to
with
the
some
to
the
were
for
the
same
i
for
with
i
to
more
i
to
that
have
to
the
these
are
not
if
you
these
in
your
on
until
you
them
i
the
and
them
into
so
of
this
you
this
but
the
some
of
the
to
after
they
were
and
then
that
was
a
the
there
are
and
and
that
have
had
there
is
no
a
for
to
you
in
as
the
to
the
for
the
same
the
no
the
of
has
been
when
you
you
had
to
which
were
the
to
the
is
no
any
to
be
an
if
you
a
to
an
it
being
an
an
or
is
into
the
had
a
of
of
with
which
have
been
the
no
the
or
has
but
its
is
to
into
the
and
have
been
they
a
some
but
not
all
into
that
no
if
you
to
into
on
than
them
into
you
to
an
if
a
a
and
then
is
the
same
as
it
was
have
of
as
their
not
this
the
you
by
if
you
of
the
both
and
a
for
that
your
and
your
for
it
not
the
themselves
the
and
for
the
no
the
its
the
to
the
and
have
been
its
the
how
to
the
a
not
a
of
this
or
a
or
beautiful
soup
documentation
beautiful
soup
documentation
navigation
beautiful
soup
documentation
beautiful
soup
is
a
python
library
for
pulling
data
out
of
html
and
xml
files
it
works
with
your
favorite
parser
to
provide
idiomatic
ways
of
navigating
searching
and
modifying
the
parse
tree
it
commonly
saves
programmers
hours
or
days
of
work
these
instructions
illustrate
all
major
features
of
beautiful
soup
with
examples
i
show
you
what
the
library
is
good
for
how
it
works
how
to
use
it
how
to
make
it
do
what
you
want
and
what
to
do
when
it
violates
your
expectations
the
examples
in
this
documentation
should
work
the
same
way
in
python
and
python
you
might
be
looking
for
the
documentation
for
beautiful
soup
if
so
you
should
know
that
beautiful
soup
is
no
longer
being
developed
and
that
beautiful
soup
is
recommended
for
all
new
projects
if
you
want
to
learn
about
the
differences
between
beautiful
soup
and
beautiful
soup
see
porting
code
to
bs
this
documentation
has
been
translated
into
other
languages
by
beautiful
soup
users
getting
help
if
you
have
questions
about
beautiful
soup
or
run
into
problems
send
mail
to
the
discussion
group
if
your
problem
involves
parsing
an
html
document
be
sure
to
mention
what
the
diagnose
function
says
about
that
document
quick
start
heres
an
html
document
ill
be
using
as
an
example
throughout
this
document
its
part
of
a
story
from
alice
in
wonderland
running
the
three
sisters
document
through
beautiful
soup
gives
us
a
beautifulsoup
object
which
represents
the
document
as
a
nested
data
structure
here
are
some
simple
ways
to
navigate
that
data
structure
one
common
task
is
extracting
all
the
urls
found
within
a
pages
a
tags
another
common
task
is
extracting
all
the
text
from
a
page
does
this
look
like
what
you
need
if
so
read
on
installing
beautiful
soup
if
youre
using
a
recent
version
of
debian
or
ubuntu
linux
you
can
install
beautiful
soup
with
the
system
package
manager
apt
get
install
python
bs
for
python
apt
get
install
python
bs
for
python
beautiful
soup
is
published
through
pypi
so
if
you
cant
install
it
with
the
system
packager
you
can
install
it
with
easyinstall
or
pip
the
package
name
is
beautifulsoup
and
the
same
package
works
on
python
and
python
make
sure
you
use
the
right
version
of
pip
or
easyinstall
for
your
python
version
these
may
be
named
pip
and
easyinstall
respectively
if
youre
using
python
easyinstall
beautifulsoup
pip
install
beautifulsoup
the
beautifulsoup
package
is
probably
not
what
you
want
thats
the
previous
major
release
beautiful
soup
lots
of
software
uses
bs
so
its
still
available
but
if
youre
writing
new
code
you
should
install
beautifulsoup
if
you
dont
have
easyinstall
or
pip
installed
you
can
download
the
beautiful
soup
source
tarball
and
install
it
with
setuppy
python
setuppy
install
if
all
else
fails
the
license
for
beautiful
soup
allows
you
to
package
the
entire
library
with
your
application
you
can
download
the
tarball
copy
its
bs
directory
into
your
applications
codebase
and
use
beautiful
soup
without
installing
it
at
all
i
use
python
and
python
to
develop
beautiful
soup
but
it
should
work
with
other
recent
versions
problems
after
installation
beautiful
soup
is
packaged
as
python
code
when
you
install
it
for
use
with
python
its
automatically
converted
to
python
code
if
you
dont
install
the
package
the
code
wont
be
converted
there
have
also
been
reports
on
windows
machines
of
the
wrong
version
being
installed
if
you
get
the
importerror
no
module
named
htmlparser
your
problem
is
that
youre
running
the
python
version
of
the
code
under
python
if
you
get
the
importerror
no
module
named
htmlparser
your
problem
is
that
youre
running
the
python
version
of
the
code
under
python
in
both
cases
your
best
bet
is
to
completely
remove
the
beautiful
soup
installation
from
your
system
including
any
directory
created
when
you
unzipped
the
tarball
and
try
the
installation
again
if
you
get
the
syntaxerror
invalid
syntax
on
the
line
roottagname
udocument
you
need
to
convert
the
python
code
to
python
you
can
do
this
either
by
installing
the
package
python
setuppy
install
or
by
manually
running
pythons
to
conversion
script
on
the
bs
directory
to
w
bs
installing
a
parser
beautiful
soup
supports
the
html
parser
included
in
pythons
standard
library
but
it
also
supports
a
number
of
third
party
python
parsers
one
is
the
lxml
parser
depending
on
your
setup
you
might
install
lxml
with
one
of
these
commands
apt
get
install
python
lxml
easyinstall
lxml
pip
install
lxml
another
alternative
is
the
pure
python
htmllib
parser
which
parses
html
the
way
a
web
browser
does
depending
on
your
setup
you
might
install
htmllib
with
one
of
these
commands
apt
get
install
python
htmllib
easyinstall
htmllib
pip
install
htmllib
this
table
summarizes
the
advantages
and
disadvantages
of
each
parser
library
if
you
can
i
recommend
you
install
and
use
lxml
for
speed
if
youre
using
a
version
of
python
earlier
than
or
a
version
of
python
earlier
than
its
essential
that
you
install
lxml
or
htmllibpythons
built
in
html
parser
is
just
not
very
good
in
older
versions
note
that
if
a
document
is
invalid
different
parsers
will
generate
different
beautiful
soup
trees
for
it
see
differences
between
parsers
for
details
making
the
soup
to
parse
a
document
pass
it
into
the
beautifulsoup
constructor
you
can
pass
in
a
string
or
an
open
filehandle
first
the
document
is
converted
to
unicode
and
html
entities
are
converted
to
unicode
characters
beautiful
soup
then
parses
the
document
using
the
best
available
parser
it
will
use
an
html
parser
unless
you
specifically
tell
it
to
use
an
xml
parser
see
parsing
xml
kinds
of
objects
beautiful
soup
transforms
a
complex
html
document
into
a
complex
tree
of
python
objects
but
youll
only
ever
have
to
deal
with
about
four
kinds
of
objects
tag
navigablestring
beautifulsoup
and
comment
tag
a
tag
object
corresponds
to
an
xml
or
html
tag
in
the
original
document
tags
have
a
lot
of
attributes
and
methods
and
ill
cover
most
of
them
in
navigating
the
tree
and
searching
the
tree
for
now
the
most
important
features
of
a
tag
are
its
name
and
attributes
name
every
tag
has
a
name
accessible
as
name
if
you
change
a
tags
name
the
change
will
be
reflected
in
any
html
markup
generated
by
beautiful
soup
attributes
a
tag
may
have
any
number
of
attributes
the
tag
b
idboldest
has
an
attribute
id
whose
value
is
boldest
you
can
access
a
tags
attributes
by
treating
the
tag
like
a
dictionary
you
can
access
that
dictionary
directly
as
attrs
you
can
add
remove
and
modify
a
tags
attributes
again
this
is
done
by
treating
the
tag
as
a
dictionary
multi
valued
attributes
html
defines
a
few
attributes
that
can
have
multiple
values
html
removes
a
couple
of
them
but
defines
a
few
more
the
most
common
multi
valued
attribute
is
class
that
is
a
tag
can
have
more
than
one
css
class
others
include
rel
rev
accept
charset
headers
and
accesskey
beautiful
soup
presents
the
values
of
a
multi
valued
attribute
as
a
list
if
an
attribute
looks
like
it
has
more
than
one
value
but
its
not
a
multi
valued
attribute
as
defined
by
any
version
of
the
html
standard
beautiful
soup
will
leave
the
attribute
alone
when
you
turn
a
tag
back
into
a
string
multiple
attribute
values
are
consolidated
you
can
disable
this
by
passing
multivaluedattributesnone
as
a
keyword
argument
into
the
beautifulsoup
constructor
you
can
use
getattributelist
to
get
a
value
thats
always
a
list
whether
or
not
its
a
multi
valued
atribute
if
you
parse
a
document
as
xml
there
are
no
multi
valued
attributes
again
you
can
configure
this
using
the
multivaluedattributes
argument
you
probably
wont
need
to
do
this
but
if
you
do
use
the
defaults
as
a
guide
they
implement
the
rules
described
in
the
html
specification
navigablestring
a
string
corresponds
to
a
bit
of
text
within
a
tag
beautiful
soup
uses
the
navigablestring
class
to
contain
these
bits
of
text
a
navigablestring
is
just
like
a
python
unicode
string
except
that
it
also
supports
some
of
the
features
described
in
navigating
the
tree
and
searching
the
tree
you
can
convert
a
navigablestring
to
a
unicode
string
with
unicode
you
cant
edit
a
string
in
place
but
you
can
replace
one
string
with
another
using
replacewith
navigablestring
supports
most
of
the
features
described
in
navigating
the
tree
and
searching
the
tree
but
not
all
of
them
in
particular
since
a
string
cant
contain
anything
the
way
a
tag
may
contain
a
string
or
another
tag
strings
dont
support
the
contents
or
string
attributes
or
the
find
method
if
you
want
to
use
a
navigablestring
outside
of
beautiful
soup
you
should
call
unicode
on
it
to
turn
it
into
a
normal
python
unicode
string
if
you
dont
your
string
will
carry
around
a
reference
to
the
entire
beautiful
soup
parse
tree
even
when
youre
done
using
beautiful
soup
this
is
a
big
waste
of
memory
beautifulsoup
the
beautifulsoup
object
itself
represents
the
document
as
a
whole
for
most
purposes
you
can
treat
it
as
a
tag
object
this
means
it
supports
most
of
the
methods
described
in
navigating
the
tree
and
searching
the
tree
since
the
beautifulsoup
object
doesnt
correspond
to
an
actual
html
or
xml
tag
it
has
no
name
and
no
attributes
but
sometimes
its
useful
to
look
at
its
name
so
its
been
given
the
special
name
document
comments
and
other
special
strings
tag
navigablestring
and
beautifulsoup
cover
almost
everything
youll
see
in
an
html
or
xml
file
but
there
are
a
few
leftover
bits
the
only
one
youll
probably
ever
need
to
worry
about
is
the
comment
the
comment
object
is
just
a
special
type
of
navigablestring
but
when
it
appears
as
part
of
an
html
document
a
comment
is
displayed
with
special
formatting
beautiful
soup
defines
classes
for
anything
else
that
might
show
up
in
an
xml
document
cdata
processinginstruction
declaration
and
doctype
just
like
comment
these
classes
are
subclasses
of
navigablestring
that
add
something
extra
to
the
string
heres
an
example
that
replaces
the
comment
with
a
cdata
block
navigating
the
tree
heres
the
three
sisters
html
document
again
ill
use
this
as
an
example
to
show
you
how
to
move
from
one
part
of
a
document
to
another
going
down
tags
may
contain
strings
and
other
tags
these
elements
are
the
tags
children
beautiful
soup
provides
a
lot
of
different
attributes
for
navigating
and
iterating
over
a
tags
children
note
that
beautiful
soup
strings
dont
support
any
of
these
attributes
because
a
string
cant
have
children
navigating
using
tag
names
the
simplest
way
to
navigate
the
parse
tree
is
to
say
the
name
of
the
tag
you
want
if
you
want
the
head
tag
just
say
souphead
you
can
do
use
this
trick
again
and
again
to
zoom
in
on
a
certain
part
of
the
parse
tree
this
code
gets
the
first
b
tag
beneath
the
body
tag
using
a
tag
name
as
an
attribute
will
give
you
only
the
first
tag
by
that
name
if
you
need
to
get
all
the
a
tags
or
anything
more
complicated
than
the
first
tag
with
a
certain
name
youll
need
to
use
one
of
the
methods
described
in
searching
the
tree
such
as
findall
contents
and
children
a
tags
children
are
available
in
a
list
called
contents
the
beautifulsoup
object
itself
has
children
in
this
case
the
html
tag
is
the
child
of
the
beautifulsoup
object
a
string
does
not
have
contents
because
it
cant
contain
anything
instead
of
getting
them
as
a
list
you
can
iterate
over
a
tags
children
using
the
children
generator
descendants
the
contents
and
children
attributes
only
consider
a
tags
direct
children
for
instance
the
head
tag
has
a
single
direct
childthe
title
tag
but
the
title
tag
itself
has
a
child
the
string
the
dormouses
story
theres
a
sense
in
which
that
string
is
also
a
child
of
the
head
tag
the
descendants
attribute
lets
you
iterate
over
all
of
a
tags
children
recursively
its
direct
children
the
children
of
its
direct
children
and
so
on
the
head
tag
has
only
one
child
but
it
has
two
descendants
the
title
tag
and
the
title
tags
child
the
beautifulsoup
object
only
has
one
direct
child
the
html
tag
but
it
has
a
whole
lot
of
descendants
string
if
a
tag
has
only
one
child
and
that
child
is
a
navigablestring
the
child
is
made
available
as
string
if
a
tags
only
child
is
another
tag
and
that
tag
has
a
string
then
the
parent
tag
is
considered
to
have
the
same
string
as
its
child
if
a
tag
contains
more
than
one
thing
then
its
not
clear
what
string
should
refer
to
so
string
is
defined
to
be
none
strings
and
strippedstrings
if
theres
more
than
one
thing
inside
a
tag
you
can
still
look
at
just
the
strings
use
the
strings
generator
these
strings
tend
to
have
a
lot
of
extra
whitespace
which
you
can
remove
by
using
the
strippedstrings
generator
instead
here
strings
consisting
entirely
of
whitespace
are
ignored
and
whitespace
at
the
beginning
and
end
of
strings
is
removed
going
up
continuing
the
family
tree
analogy
every
tag
and
every
string
has
a
parent
the
tag
that
contains
it
parent
you
can
access
an
elements
parent
with
the
parent
attribute
in
the
example
three
sisters
document
the
head
tag
is
the
parent
of
the
title
tag
the
title
string
itself
has
a
parent
the
title
tag
that
contains
it
the
parent
of
a
top
level
tag
like
html
is
the
beautifulsoup
object
itself
and
the
parent
of
a
beautifulsoup
object
is
defined
as
none
parents
you
can
iterate
over
all
of
an
elements
parents
with
parents
this
example
uses
parents
to
travel
from
an
a
tag
buried
deep
within
the
document
to
the
very
top
of
the
document
going
sideways
consider
a
simple
document
like
this
the
b
tag
and
the
c
tag
are
at
the
same
level
theyre
both
direct
children
of
the
same
tag
we
call
them
siblings
when
a
document
is
pretty
printed
siblings
show
up
at
the
same
indentation
level
you
can
also
use
this
relationship
in
the
code
you
write
nextsibling
and
previoussibling
you
can
use
nextsibling
and
previoussibling
to
navigate
between
page
elements
that
are
on
the
same
level
of
the
parse
tree
the
b
tag
has
a
nextsibling
but
no
previoussibling
because
theres
nothing
before
the
b
tag
on
the
same
level
of
the
tree
for
the
same
reason
the
c
tag
has
a
previoussibling
but
no
nextsibling
the
strings
text
and
text
are
not
siblings
because
they
dont
have
the
same
parent
in
real
documents
the
nextsibling
or
previoussibling
of
a
tag
will
usually
be
a
string
containing
whitespace
going
back
to
the
three
sisters
document
you
might
think
that
the
nextsibling
of
the
first
a
tag
would
be
the
second
a
tag
but
actually
its
a
string
the
comma
and
newline
that
separate
the
first
a
tag
from
the
second
the
second
a
tag
is
actually
the
nextsibling
of
the
comma
nextsiblings
and
previoussiblings
you
can
iterate
over
a
tags
siblings
with
nextsiblings
or
previoussiblings
going
back
and
forth
take
a
look
at
the
beginning
of
the
three
sisters
document
an
html
parser
takes
this
string
of
characters
and
turns
it
into
a
series
of
events
open
an
html
tag
open
a
head
tag
open
a
title
tag
add
a
string
close
the
title
tag
open
a
p
tag
and
so
on
beautiful
soup
offers
tools
for
reconstructing
the
initial
parse
of
the
document
nextelement
and
previouselement
the
nextelement
attribute
of
a
string
or
tag
points
to
whatever
was
parsed
immediately
afterwards
it
might
be
the
same
as
nextsibling
but
its
usually
drastically
different
heres
the
final
a
tag
in
the
three
sisters
document
its
nextsibling
is
a
string
the
conclusion
of
the
sentence
that
was
interrupted
by
the
start
of
the
a
tag
but
the
nextelement
of
that
a
tag
the
thing
that
was
parsed
immediately
after
the
a
tag
is
not
the
rest
of
that
sentence
its
the
word
tillie
thats
because
in
the
original
markup
the
word
tillie
appeared
before
that
semicolon
the
parser
encountered
an
a
tag
then
the
word
tillie
then
the
closing
a
tag
then
the
semicolon
and
rest
of
the
sentence
the
semicolon
is
on
the
same
level
as
the
a
tag
but
the
word
tillie
was
encountered
first
the
previouselement
attribute
is
the
exact
opposite
of
nextelement
it
points
to
whatever
element
was
parsed
immediately
before
this
one
nextelements
and
previouselements
you
should
get
the
idea
by
now
you
can
use
these
iterators
to
move
forward
or
backward
in
the
document
as
it
was
parsed
searching
the
tree
beautiful
soup
defines
a
lot
of
methods
for
searching
the
parse
tree
but
theyre
all
very
similar
im
going
to
spend
a
lot
of
time
explaining
the
two
most
popular
methods
find
and
findall
the
other
methods
take
almost
exactly
the
same
arguments
so
ill
just
cover
them
briefly
once
again
ill
be
using
the
three
sisters
document
as
an
example
by
passing
in
a
filter
to
an
argument
like
findall
you
can
zoom
in
on
the
parts
of
the
document
youre
interested
in
kinds
of
filters
before
talking
in
detail
about
findall
and
similar
methods
i
want
to
show
examples
of
different
filters
you
can
pass
into
these
methods
these
filters
show
up
again
and
again
throughout
the
search
api
you
can
use
them
to
filter
based
on
a
tags
name
on
its
attributes
on
the
text
of
a
string
or
on
some
combination
of
these
a
string
the
simplest
filter
is
a
string
pass
a
string
to
a
search
method
and
beautiful
soup
will
perform
a
match
against
that
exact
string
this
code
finds
all
the
b
tags
in
the
document
if
you
pass
in
a
byte
string
beautiful
soup
will
assume
the
string
is
encoded
as
utf
you
can
avoid
this
by
passing
in
a
unicode
string
instead
a
regular
expression
if
you
pass
in
a
regular
expression
object
beautiful
soup
will
filter
against
that
regular
expression
using
its
search
method
this
code
finds
all
the
tags
whose
names
start
with
the
letter
b
in
this
case
the
body
tag
and
the
b
tag
this
code
finds
all
the
tags
whose
names
contain
the
letter
t
a
list
if
you
pass
in
a
list
beautiful
soup
will
allow
a
string
match
against
any
item
in
that
list
this
code
finds
all
the
a
tags
and
all
the
b
tags
true
the
value
true
matches
everything
it
can
this
code
finds
all
the
tags
in
the
document
but
none
of
the
text
strings
a
function
if
none
of
the
other
matches
work
for
you
define
a
function
that
takes
an
element
as
its
only
argument
the
function
should
return
true
if
the
argument
matches
and
false
otherwise
heres
a
function
that
returns
true
if
a
tag
defines
the
class
attribute
but
doesnt
define
the
id
attribute
pass
this
function
into
findall
and
youll
pick
up
all
the
p
tags
this
function
only
picks
up
the
p
tags
it
doesnt
pick
up
the
a
tags
because
those
tags
define
both
class
and
id
it
doesnt
pick
up
tags
like
html
and
title
because
those
tags
dont
define
class
if
you
pass
in
a
function
to
filter
on
a
specific
attribute
like
href
the
argument
passed
into
the
function
will
be
the
attribute
value
not
the
whole
tag
heres
a
function
that
finds
all
a
tags
whose
href
attribute
does
not
match
a
regular
expression
the
function
can
be
as
complicated
as
you
need
it
to
be
heres
a
function
that
returns
true
if
a
tag
is
surrounded
by
string
objects
now
were
ready
to
look
at
the
search
methods
in
detail
findall
signature
findall
name
attrs
recursive
string
limit
kwargs
the
findall
method
looks
through
a
tags
descendants
and
retrieves
all
descendants
that
match
your
filters
i
gave
several
examples
in
kinds
of
filters
but
here
are
a
few
more
some
of
these
should
look
familiar
but
others
are
new
what
does
it
mean
to
pass
in
a
value
for
string
or
id
why
does
findallp
title
find
a
p
tag
with
the
css
class
title
lets
look
at
the
arguments
to
findall
the
name
argument
pass
in
a
value
for
name
and
youll
tell
beautiful
soup
to
only
consider
tags
with
certain
names
text
strings
will
be
ignored
as
will
tags
whose
names
that
dont
match
this
is
the
simplest
usage
recall
from
kinds
of
filters
that
the
value
to
name
can
be
a
string
a
regular
expression
a
list
a
function
or
the
value
true
the
keyword
arguments
any
argument
thats
not
recognized
will
be
turned
into
a
filter
on
one
of
a
tags
attributes
if
you
pass
in
a
value
for
an
argument
called
id
beautiful
soup
will
filter
against
each
tags
id
attribute
if
you
pass
in
a
value
for
href
beautiful
soup
will
filter
against
each
tags
href
attribute
you
can
filter
an
attribute
based
on
a
string
a
regular
expression
a
list
a
function
or
the
value
true
this
code
finds
all
tags
whose
id
attribute
has
a
value
regardless
of
what
the
value
is
you
can
filter
multiple
attributes
at
once
by
passing
in
more
than
one
keyword
argument
some
attributes
like
the
data
attributes
in
html
have
names
that
cant
be
used
as
the
names
of
keyword
arguments
you
can
use
these
attributes
in
searches
by
putting
them
into
a
dictionary
and
passing
the
dictionary
into
findall
as
the
attrs
argument
you
cant
use
a
keyword
argument
to
search
for
htmls
name
element
because
beautiful
soup
uses
the
name
argument
to
contain
the
name
of
the
tag
itself
instead
you
can
give
a
value
to
name
in
the
attrs
argument
searching
by
css
class
its
very
useful
to
search
for
a
tag
that
has
a
certain
css
class
but
the
name
of
the
css
attribute
class
is
a
reserved
word
in
python
using
class
as
a
keyword
argument
will
give
you
a
syntax
error
as
of
beautiful
soup
you
can
search
by
css
class
using
the
keyword
argument
class
as
with
any
keyword
argument
you
can
pass
class
a
string
a
regular
expression
a
function
or
true
remember
that
a
single
tag
can
have
multiple
values
for
its
class
attribute
when
you
search
for
a
tag
that
matches
a
certain
css
class
youre
matching
against
any
of
its
css
classes
you
can
also
search
for
the
exact
string
value
of
the
class
attribute
but
searching
for
variants
of
the
string
value
wont
work
if
you
want
to
search
for
tags
that
match
two
or
more
css
classes
you
should
use
a
css
selector
in
older
versions
of
beautiful
soup
which
dont
have
the
class
shortcut
you
can
use
the
attrs
trick
mentioned
above
create
a
dictionary
whose
value
for
class
is
the
string
or
regular
expression
or
whatever
you
want
to
search
for
the
string
argument
with
string
you
can
search
for
strings
instead
of
tags
as
with
name
and
the
keyword
arguments
you
can
pass
in
a
string
a
regular
expression
a
list
a
function
or
the
value
true
here
are
some
examples
although
string
is
for
finding
strings
you
can
combine
it
with
arguments
that
find
tags
beautiful
soup
will
find
all
tags
whose
string
matches
your
value
for
string
this
code
finds
the
a
tags
whose
string
is
elsie
the
string
argument
is
new
in
beautiful
soup
in
earlier
versions
it
was
called
text
the
limit
argument
findall
returns
all
the
tags
and
strings
that
match
your
filters
this
can
take
a
while
if
the
document
is
large
if
you
dont
need
all
the
results
you
can
pass
in
a
number
for
limit
this
works
just
like
the
limit
keyword
in
sql
it
tells
beautiful
soup
to
stop
gathering
results
after
its
found
a
certain
number
there
are
three
links
in
the
three
sisters
document
but
this
code
only
finds
the
first
two
the
recursive
argument
if
you
call
mytagfindall
beautiful
soup
will
examine
all
the
descendants
of
mytag
its
children
its
childrens
children
and
so
on
if
you
only
want
beautiful
soup
to
consider
direct
children
you
can
pass
in
recursivefalse
see
the
difference
here
heres
that
part
of
the
document
the
title
tag
is
beneath
the
html
tag
but
its
not
directly
beneath
the
html
tag
the
head
tag
is
in
the
way
beautiful
soup
finds
the
title
tag
when
its
allowed
to
look
at
all
descendants
of
the
html
tag
but
when
recursivefalse
restricts
it
to
the
html
tags
immediate
children
it
finds
nothing
beautiful
soup
offers
a
lot
of
tree
searching
methods
covered
below
and
they
mostly
take
the
same
arguments
as
findall
name
attrs
string
limit
and
the
keyword
arguments
but
the
recursive
argument
is
different
findall
and
find
are
the
only
methods
that
support
it
passing
recursivefalse
into
a
method
like
findparents
wouldnt
be
very
useful
calling
a
tag
is
like
calling
findall
because
findall
is
the
most
popular
method
in
the
beautiful
soup
search
api
you
can
use
a
shortcut
for
it
if
you
treat
the
beautifulsoup
object
or
a
tag
object
as
though
it
were
a
function
then
its
the
same
as
calling
findall
on
that
object
these
two
lines
of
code
are
equivalent
these
two
lines
are
also
equivalent
find
signature
find
name
attrs
recursive
string
kwargs
the
findall
method
scans
the
entire
document
looking
for
results
but
sometimes
you
only
want
to
find
one
result
if
you
know
a
document
only
has
one
body
tag
its
a
waste
of
time
to
scan
the
entire
document
looking
for
more
rather
than
passing
in
limit
every
time
you
call
findall
you
can
use
the
find
method
these
two
lines
of
code
are
nearly
equivalent
the
only
difference
is
that
findall
returns
a
list
containing
the
single
result
and
find
just
returns
the
result
if
findall
cant
find
anything
it
returns
an
empty
list
if
find
cant
find
anything
it
returns
none
remember
the
soupheadtitle
trick
from
navigating
using
tag
names
that
trick
works
by
repeatedly
calling
find
findparents
and
findparent
signature
findparents
name
attrs
string
limit
kwargs
signature
findparent
name
attrs
string
kwargs
i
spent
a
lot
of
time
above
covering
findall
and
find
the
beautiful
soup
api
defines
ten
other
methods
for
searching
the
tree
but
dont
be
afraid
five
of
these
methods
are
basically
the
same
as
findall
and
the
other
five
are
basically
the
same
as
find
the
only
differences
are
in
what
parts
of
the
tree
they
search
first
lets
consider
findparents
and
findparent
remember
that
findall
and
find
work
their
way
down
the
tree
looking
at
tags
descendants
these
methods
do
the
opposite
they
work
their
way
up
the
tree
looking
at
a
tags
or
a
strings
parents
lets
try
them
out
starting
from
a
string
buried
deep
in
the
three
daughters
document
one
of
the
three
a
tags
is
the
direct
parent
of
the
string
in
question
so
our
search
finds
it
one
of
the
three
p
tags
is
an
indirect
parent
of
the
string
and
our
search
finds
that
as
well
theres
a
p
tag
with
the
css
class
title
somewhere
in
the
document
but
its
not
one
of
this
strings
parents
so
we
cant
find
it
with
findparents
you
may
have
made
the
connection
between
findparent
and
findparents
and
the
parent
and
parents
attributes
mentioned
earlier
the
connection
is
very
strong
these
search
methods
actually
use
parents
to
iterate
over
all
the
parents
and
check
each
one
against
the
provided
filter
to
see
if
it
matches
findnextsiblings
and
findnextsibling
signature
findnextsiblings
name
attrs
string
limit
kwargs
signature
findnextsibling
name
attrs
string
kwargs
these
methods
use
nextsiblings
to
iterate
over
the
rest
of
an
elements
siblings
in
the
tree
the
findnextsiblings
method
returns
all
the
siblings
that
match
and
findnextsibling
only
returns
the
first
one
findprevioussiblings
and
findprevioussibling
signature
findprevioussiblings
name
attrs
string
limit
kwargs
signature
findprevioussibling
name
attrs
string
kwargs
these
methods
use
previoussiblings
to
iterate
over
an
elements
siblings
that
precede
it
in
the
tree
the
findprevioussiblings
method
returns
all
the
siblings
that
match
and
findprevioussibling
only
returns
the
first
one
findallnext
and
findnext
signature
findallnext
name
attrs
string
limit
kwargs
signature
findnext
name
attrs
string
kwargs
these
methods
use
nextelements
to
iterate
over
whatever
tags
and
strings
that
come
after
it
in
the
document
the
findallnext
method
returns
all
matches
and
findnext
only
returns
the
first
match
in
the
first
example
the
string
elsie
showed
up
even
though
it
was
contained
within
the
a
tag
we
started
from
in
the
second
example
the
last
p
tag
in
the
document
showed
up
even
though
its
not
in
the
same
part
of
the
tree
as
the
a
tag
we
started
from
for
these
methods
all
that
matters
is
that
an
element
match
the
filter
and
show
up
later
in
the
document
than
the
starting
element
findallprevious
and
findprevious
signature
findallprevious
name
attrs
string
limit
kwargs
signature
findprevious
name
attrs
string
kwargs
these
methods
use
previouselements
to
iterate
over
the
tags
and
strings
that
came
before
it
in
the
document
the
findallprevious
method
returns
all
matches
and
findprevious
only
returns
the
first
match
the
call
to
findallpreviousp
found
the
first
paragraph
in
the
document
the
one
with
classtitle
but
it
also
finds
the
second
paragraph
the
p
tag
that
contains
the
a
tag
we
started
with
this
shouldnt
be
too
surprising
were
looking
at
all
the
tags
that
show
up
earlier
in
the
document
than
the
one
we
started
with
a
p
tag
that
contains
an
a
tag
must
have
shown
up
before
the
a
tag
it
contains
css
selectors
as
of
version
beautiful
soup
supports
most
css
selectors
via
the
soupsieve
project
if
you
installed
beautiful
soup
through
pip
soupsieve
was
installed
at
the
same
time
so
you
dont
have
to
do
anything
extra
beautifulsoup
has
a
select
method
which
uses
soupsieve
to
run
a
css
selector
against
a
parsed
document
and
return
all
the
matching
elements
tag
has
a
similar
method
which
runs
a
css
selector
against
the
contents
of
a
single
tag
earlier
versions
of
beautiful
soup
also
have
the
select
method
but
only
the
most
commonly
used
css
selectors
are
supported
the
soupsieve
documentation
lists
all
the
currently
supported
css
selectors
but
here
are
some
of
the
basics
you
can
find
tags
find
tags
beneath
other
tags
find
tags
directly
beneath
other
tags
find
the
siblings
of
tags
find
tags
by
css
class
find
tags
by
id
find
tags
that
match
any
selector
from
a
list
of
selectors
test
for
the
existence
of
an
attribute
find
tags
by
attribute
value
theres
also
a
method
called
selectone
which
finds
only
the
first
tag
that
matches
a
selector
if
youve
parsed
xml
that
defines
namespaces
you
can
use
them
in
css
selectors
when
handling
a
css
selector
that
uses
namespaces
beautiful
soup
uses
the
namespace
abbreviations
it
found
when
parsing
the
document
you
can
override
this
by
passing
in
your
own
dictionary
of
abbreviations
all
this
css
selector
stuff
is
a
convenience
for
people
who
already
know
the
css
selector
syntax
you
can
do
all
of
this
with
the
beautiful
soup
api
and
if
css
selectors
are
all
you
need
you
should
parse
the
document
with
lxml
its
a
lot
faster
but
this
lets
you
combine
css
selectors
with
the
beautiful
soup
api
modifying
the
tree
beautiful
soups
main
strength
is
in
searching
the
parse
tree
but
you
can
also
modify
the
tree
and
write
your
changes
as
a
new
html
or
xml
document
changing
tag
names
and
attributes
i
covered
this
earlier
in
attributes
but
it
bears
repeating
you
can
rename
a
tag
change
the
values
of
its
attributes
add
new
attributes
and
delete
attributes
modifying
string
if
you
set
a
tags
string
attribute
the
tags
contents
are
replaced
with
the
string
you
give
be
careful
if
the
tag
contained
other
tags
they
and
all
their
contents
will
be
destroyed
append
you
can
add
to
a
tags
contents
with
tagappend
it
works
just
like
calling
append
on
a
python
list
extend
starting
in
beautiful
soup
tag
also
supports
a
method
called
extend
which
works
just
like
calling
extend
on
a
python
list
navigablestring
and
newtag
if
you
need
to
add
a
string
to
a
document
no
problemyou
can
pass
a
python
string
in
to
append
or
you
can
call
the
navigablestring
constructor
if
you
want
to
create
a
comment
or
some
other
subclass
of
navigablestring
just
call
the
constructor
this
is
a
new
feature
in
beautiful
soup
what
if
you
need
to
create
a
whole
new
tag
the
best
solution
is
to
call
the
factory
method
beautifulsoupnewtag
only
the
first
argument
the
tag
name
is
required
insert
taginsert
is
just
like
tagappend
except
the
new
element
doesnt
necessarily
go
at
the
end
of
its
parents
contents
itll
be
inserted
at
whatever
numeric
position
you
say
it
works
just
like
insert
on
a
python
list
insertbefore
and
insertafter
the
insertbefore
method
inserts
tags
or
strings
immediately
before
something
else
in
the
parse
tree
the
insertafter
method
inserts
tags
or
strings
immediately
following
something
else
in
the
parse
tree
clear
tagclear
removes
the
contents
of
a
tag
extract
pageelementextract
removes
a
tag
or
string
from
the
tree
it
returns
the
tag
or
string
that
was
extracted
at
this
point
you
effectively
have
two
parse
trees
one
rooted
at
the
beautifulsoup
object
you
used
to
parse
the
document
and
one
rooted
at
the
tag
that
was
extracted
you
can
go
on
to
call
extract
on
a
child
of
the
element
you
extracted
decompose
tagdecompose
removes
a
tag
from
the
tree
then
completely
destroys
it
and
its
contents
replacewith
pageelementreplacewith
removes
a
tag
or
string
from
the
tree
and
replaces
it
with
the
tag
or
string
of
your
choice
replacewith
returns
the
tag
or
string
that
was
replaced
so
that
you
can
examine
it
or
add
it
back
to
another
part
of
the
tree
wrap
pageelementwrap
wraps
an
element
in
the
tag
you
specify
it
returns
the
new
wrapper
this
method
is
new
in
beautiful
soup
unwrap
tagunwrap
is
the
opposite
of
wrap
it
replaces
a
tag
with
whatevers
inside
that
tag
its
good
for
stripping
out
markup
like
replacewith
unwrap
returns
the
tag
that
was
replaced
smooth
after
calling
a
bunch
of
methods
that
modify
the
parse
tree
you
may
end
up
with
two
or
more
navigablestring
objects
next
to
each
other
beautiful
soup
doesnt
have
any
problems
with
this
but
since
it
cant
happen
in
a
freshly
parsed
document
you
might
not
expect
behavior
like
the
following
you
can
call
tagsmooth
to
clean
up
the
parse
tree
by
consolidating
adjacent
strings
the
smooth
method
is
new
in
beautiful
soup
output
pretty
printing
the
prettify
method
will
turn
a
beautiful
soup
parse
tree
into
a
nicely
formatted
unicode
string
with
a
separate
line
for
each
tag
and
each
string
you
can
call
prettify
on
the
top
level
beautifulsoup
object
or
on
any
of
its
tag
objects
non
pretty
printing
if
you
just
want
a
string
with
no
fancy
formatting
you
can
call
unicode
or
str
on
a
beautifulsoup
object
or
a
tag
within
it
the
str
function
returns
a
string
encoded
in
utf
see
encodings
for
other
options
you
can
also
call
encode
to
get
a
bytestring
and
decode
to
get
unicode
output
formatters
if
you
give
beautiful
soup
a
document
that
contains
html
entities
like
lquot
theyll
be
converted
to
unicode
characters
if
you
then
convert
the
document
to
a
string
the
unicode
characters
will
be
encoded
as
utf
you
wont
get
the
html
entities
back
by
default
the
only
characters
that
are
escaped
upon
output
are
bare
ampersands
and
angle
brackets
these
get
turned
into
amp
lt
and
gt
so
that
beautiful
soup
doesnt
inadvertently
generate
invalid
html
or
xml
you
can
change
this
behavior
by
providing
a
value
for
the
formatter
argument
to
prettify
encode
or
decode
beautiful
soup
recognizes
five
possible
values
for
formatter
the
default
is
formatterminimal
strings
will
only
be
processed
enough
to
ensure
that
beautiful
soup
generates
valid
htmlxml
if
you
pass
in
formatterhtml
beautiful
soup
will
convert
unicode
characters
to
html
entities
whenever
possible
if
you
pass
in
formatterhtml
its
the
same
as
formatterhtml
but
beautiful
soup
will
omit
the
closing
slash
in
html
void
tags
like
br
if
you
pass
in
formatternone
beautiful
soup
will
not
modify
strings
at
all
on
output
this
is
the
fastest
option
but
it
may
lead
to
beautiful
soup
generating
invalid
htmlxml
as
in
these
examples
if
you
need
more
sophisticated
control
over
your
output
you
can
use
beautiful
soups
formatter
class
heres
a
formatter
that
converts
strings
to
uppercase
whether
they
occur
in
a
text
node
or
in
an
attribute
value
subclassing
htmlformatter
or
xmlformatter
will
give
you
even
more
control
over
the
output
for
example
beautiful
soup
sorts
the
attributes
in
every
tag
by
default
to
turn
this
off
you
can
subclass
the
formatterattributes
method
which
controls
which
attributes
are
output
and
in
what
order
this
implementation
also
filters
out
the
m
attribute
whenever
it
appears
one
last
caveat
if
you
create
a
cdata
object
the
text
inside
that
object
is
always
presented
exactly
as
it
appears
with
no
formatting
beautiful
soup
will
call
the
formatter
method
just
in
case
youve
written
a
custom
method
that
counts
all
the
strings
in
the
document
or
something
but
it
will
ignore
the
return
value
gettext
if
you
only
want
the
text
part
of
a
document
or
tag
you
can
use
the
gettext
method
it
returns
all
the
text
in
a
document
or
beneath
a
tag
as
a
single
unicode
string
you
can
specify
a
string
to
be
used
to
join
the
bits
of
text
together
you
can
tell
beautiful
soup
to
strip
whitespace
from
the
beginning
and
end
of
each
bit
of
text
but
at
that
point
you
might
want
to
use
the
strippedstrings
generator
instead
and
process
the
text
yourself
specifying
the
parser
to
use
if
you
just
need
to
parse
some
html
you
can
dump
the
markup
into
the
beautifulsoup
constructor
and
itll
probably
be
fine
beautiful
soup
will
pick
a
parser
for
you
and
parse
the
data
but
there
are
a
few
additional
arguments
you
can
pass
in
to
the
constructor
to
change
which
parser
is
used
the
first
argument
to
the
beautifulsoup
constructor
is
a
string
or
an
open
filehandlethe
markup
you
want
parsed
the
second
argument
is
how
youd
like
the
markup
parsed
if
you
dont
specify
anything
youll
get
the
best
html
parser
thats
installed
beautiful
soup
ranks
lxmls
parser
as
being
the
best
then
htmllibs
then
pythons
built
in
parser
you
can
override
this
by
specifying
one
of
the
following
the
section
installing
a
parser
contrasts
the
supported
parsers
if
you
dont
have
an
appropriate
parser
installed
beautiful
soup
will
ignore
your
request
and
pick
a
different
parser
right
now
the
only
supported
xml
parser
is
lxml
if
you
dont
have
lxml
installed
asking
for
an
xml
parser
wont
give
you
one
and
asking
for
lxml
wont
work
either
differences
between
parsers
beautiful
soup
presents
the
same
interface
to
a
number
of
different
parsers
but
each
parser
is
different
different
parsers
will
create
different
parse
trees
from
the
same
document
the
biggest
differences
are
between
the
html
parsers
and
the
xml
parsers
heres
a
short
document
parsed
as
html
since
an
empty
b
tag
is
not
valid
html
the
parser
turns
it
into
a
bb
tag
pair
heres
the
same
document
parsed
as
xml
running
this
requires
that
you
have
lxml
installed
note
that
the
empty
b
tag
is
left
alone
and
that
the
document
is
given
an
xml
declaration
instead
of
being
put
into
an
html
tag
there
are
also
differences
between
html
parsers
if
you
give
beautiful
soup
a
perfectly
formed
html
document
these
differences
wont
matter
one
parser
will
be
faster
than
another
but
theyll
all
give
you
a
data
structure
that
looks
exactly
like
the
original
html
document
but
if
the
document
is
not
perfectly
formed
different
parsers
will
give
different
results
heres
a
short
invalid
document
parsed
using
lxmls
html
parser
note
that
the
dangling
p
tag
is
simply
ignored
heres
the
same
document
parsed
using
htmllib
instead
of
ignoring
the
dangling
p
tag
htmllib
pairs
it
with
an
opening
p
tag
this
parser
also
adds
an
empty
head
tag
to
the
document
heres
the
same
document
parsed
with
pythons
built
in
html
parser
like
htmllib
this
parser
ignores
the
closing
p
tag
unlike
htmllib
this
parser
makes
no
attempt
to
create
a
well
formed
html
document
by
adding
a
body
tag
unlike
lxml
it
doesnt
even
bother
to
add
an
html
tag
since
the
document
ap
is
invalid
none
of
these
techniques
is
the
correct
way
to
handle
it
the
htmllib
parser
uses
techniques
that
are
part
of
the
html
standard
so
it
has
the
best
claim
on
being
the
correct
way
but
all
three
techniques
are
legitimate
differences
between
parsers
can
affect
your
script
if
youre
planning
on
distributing
your
script
to
other
people
or
running
it
on
multiple
machines
you
should
specify
a
parser
in
the
beautifulsoup
constructor
that
will
reduce
the
chances
that
your
users
parse
a
document
differently
from
the
way
you
parse
it
encodings
any
html
or
xml
document
is
written
in
a
specific
encoding
like
ascii
or
utf
but
when
you
load
that
document
into
beautiful
soup
youll
discover
its
been
converted
to
unicode
its
not
magic
that
sure
would
be
nice
beautiful
soup
uses
a
sub
library
called
unicode
dammit
to
detect
a
documents
encoding
and
convert
it
to
unicode
the
autodetected
encoding
is
available
as
the
originalencoding
attribute
of
the
beautifulsoup
object
unicode
dammit
guesses
correctly
most
of
the
time
but
sometimes
it
makes
mistakes
sometimes
it
guesses
correctly
but
only
after
a
byte
by
byte
search
of
the
document
that
takes
a
very
long
time
if
you
happen
to
know
a
documents
encoding
ahead
of
time
you
can
avoid
mistakes
and
delays
by
passing
it
to
the
beautifulsoup
constructor
as
fromencoding
heres
a
document
written
in
iso
the
document
is
so
short
that
unicode
dammit
cant
get
a
lock
on
it
and
misidentifies
it
as
iso
we
can
fix
this
by
passing
in
the
correct
fromencoding
if
you
dont
know
what
the
correct
encoding
is
but
you
know
that
unicode
dammit
is
guessing
wrong
you
can
pass
the
wrong
guesses
in
as
excludeencodings
windows
isnt
correct
but
that
encoding
is
a
compatible
superset
of
iso
so
its
close
enough
excludeencodings
is
a
new
feature
in
beautiful
soup
in
rare
cases
usually
when
a
utf
document
contains
text
written
in
a
completely
different
encoding
the
only
way
to
get
unicode
may
be
to
replace
some
characters
with
the
special
unicode
character
replacement
character
ufffd
if
unicode
dammit
needs
to
do
this
it
will
set
the
containsreplacementcharacters
attribute
to
true
on
the
unicodedammit
or
beautifulsoup
object
this
lets
you
know
that
the
unicode
representation
is
not
an
exact
representation
of
the
originalsome
data
was
lost
if
a
document
contains
but
containsreplacementcharacters
is
false
youll
know
that
the
was
there
originally
as
it
is
in
this
paragraph
and
doesnt
stand
in
for
missing
data
output
encoding
when
you
write
out
a
document
from
beautiful
soup
you
get
a
utf
document
even
if
the
document
wasnt
in
utf
to
begin
with
heres
a
document
written
in
the
latin
encoding
note
that
the
meta
tag
has
been
rewritten
to
reflect
the
fact
that
the
document
is
now
in
utf
if
you
dont
want
utf
you
can
pass
an
encoding
into
prettify
you
can
also
call
encode
on
the
beautifulsoup
object
or
any
element
in
the
soup
just
as
if
it
were
a
python
string
any
characters
that
cant
be
represented
in
your
chosen
encoding
will
be
converted
into
numeric
xml
entity
references
heres
a
document
that
includes
the
unicode
character
snowman
the
snowman
character
can
be
part
of
a
utf
document
it
looks
like
but
theres
no
representation
for
that
character
in
iso
latin
or
ascii
so
its
converted
into
for
those
encodings
unicode
dammit
you
can
use
unicode
dammit
without
using
beautiful
soup
its
useful
whenever
you
have
data
in
an
unknown
encoding
and
you
just
want
it
to
become
unicode
unicode
dammits
guesses
will
get
a
lot
more
accurate
if
you
install
the
chardet
or
cchardet
python
libraries
the
more
data
you
give
unicode
dammit
the
more
accurately
it
will
guess
if
you
have
your
own
suspicions
as
to
what
the
encoding
might
be
you
can
pass
them
in
as
a
list
unicode
dammit
has
two
special
features
that
beautiful
soup
doesnt
use
smart
quotes
you
can
use
unicode
dammit
to
convert
microsoft
smart
quotes
to
html
or
xml
entities
you
can
also
convert
microsoft
smart
quotes
to
ascii
quotes
hopefully
youll
find
this
feature
useful
but
beautiful
soup
doesnt
use
it
beautiful
soup
prefers
the
default
behavior
which
is
to
convert
microsoft
smart
quotes
to
unicode
characters
along
with
everything
else
inconsistent
encodings
sometimes
a
document
is
mostly
in
utf
but
contains
windows
characters
such
as
again
microsoft
smart
quotes
this
can
happen
when
a
website
includes
data
from
multiple
sources
you
can
use
unicodedammitdetwingle
to
turn
such
a
document
into
pure
utf
heres
a
simple
example
this
document
is
a
mess
the
snowmen
are
in
utf
and
the
quotes
are
in
windows
you
can
display
the
snowmen
or
the
quotes
but
not
both
decoding
the
document
as
utf
raises
a
unicodedecodeerror
and
decoding
it
as
windows
gives
you
gibberish
fortunately
unicodedammitdetwingle
will
convert
the
string
to
pure
utf
allowing
you
to
decode
it
to
unicode
and
display
the
snowmen
and
quote
marks
simultaneously
unicodedammitdetwingle
only
knows
how
to
handle
windows
embedded
in
utf
or
vice
versa
i
suppose
but
this
is
the
most
common
case
note
that
you
must
know
to
call
unicodedammitdetwingle
on
your
data
before
passing
it
into
beautifulsoup
or
the
unicodedammit
constructor
beautiful
soup
assumes
that
a
document
has
a
single
encoding
whatever
it
might
be
if
you
pass
it
a
document
that
contains
both
utf
and
windows
its
likely
to
think
the
whole
document
is
windows
and
the
document
will
come
out
looking
like
i
like
snowmen
unicodedammitdetwingle
is
new
in
beautiful
soup
comparing
objects
for
equality
beautiful
soup
says
that
two
navigablestring
or
tag
objects
are
equal
when
they
represent
the
same
html
or
xml
markup
in
this
example
the
two
b
tags
are
treated
as
equal
even
though
they
live
in
different
parts
of
the
object
tree
because
they
both
look
like
bpizzab
if
you
want
to
see
whether
two
variables
refer
to
exactly
the
same
object
use
is
copying
beautiful
soup
objects
you
can
use
copycopy
to
create
a
copy
of
any
tag
or
navigablestring
the
copy
is
considered
equal
to
the
original
since
it
represents
the
same
markup
as
the
original
but
its
not
the
same
object
the
only
real
difference
is
that
the
copy
is
completely
detached
from
the
original
beautiful
soup
object
tree
just
as
if
extract
had
been
called
on
it
this
is
because
two
different
tag
objects
cant
occupy
the
same
space
at
the
same
time
parsing
only
part
of
a
document
lets
say
you
want
to
use
beautiful
soup
look
at
a
documents
a
tags
its
a
waste
of
time
and
memory
to
parse
the
entire
document
and
then
go
over
it
again
looking
for
a
tags
it
would
be
much
faster
to
ignore
everything
that
wasnt
an
a
tag
in
the
first
place
the
soupstrainer
class
allows
you
to
choose
which
parts
of
an
incoming
document
are
parsed
you
just
create
a
soupstrainer
and
pass
it
in
to
the
beautifulsoup
constructor
as
the
parseonly
argument
note
that
this
feature
wont
work
if
youre
using
the
htmllib
parser
if
you
use
htmllib
the
whole
document
will
be
parsed
no
matter
what
this
is
because
htmllib
constantly
rearranges
the
parse
tree
as
it
works
and
if
some
part
of
the
document
didnt
actually
make
it
into
the
parse
tree
itll
crash
to
avoid
confusion
in
the
examples
below
ill
be
forcing
beautiful
soup
to
use
pythons
built
in
parser
soupstrainer
the
soupstrainer
class
takes
the
same
arguments
as
a
typical
method
from
searching
the
tree
name
attrs
string
and
kwargs
here
are
three
soupstrainer
objects
im
going
to
bring
back
the
three
sisters
document
one
more
time
and
well
see
what
the
document
looks
like
when
its
parsed
with
these
three
soupstrainer
objects
you
can
also
pass
a
soupstrainer
into
any
of
the
methods
covered
in
searching
the
tree
this
probably
isnt
terribly
useful
but
i
thought
id
mention
it
troubleshooting
diagnose
if
youre
having
trouble
understanding
what
beautiful
soup
does
to
a
document
pass
the
document
into
the
diagnose
function
new
in
beautiful
soup
beautiful
soup
will
print
out
a
report
showing
you
how
different
parsers
handle
the
document
and
tell
you
if
youre
missing
a
parser
that
beautiful
soup
could
be
using
just
looking
at
the
output
of
diagnose
may
show
you
how
to
solve
the
problem
even
if
not
you
can
paste
the
output
of
diagnose
when
asking
for
help
errors
when
parsing
a
document
there
are
two
different
kinds
of
parse
errors
there
are
crashes
where
you
feed
a
document
to
beautiful
soup
and
it
raises
an
exception
usually
an
htmlparserhtmlparseerror
and
there
is
unexpected
behavior
where
a
beautiful
soup
parse
tree
looks
a
lot
different
than
the
document
used
to
create
it
almost
none
of
these
problems
turn
out
to
be
problems
with
beautiful
soup
this
is
not
because
beautiful
soup
is
an
amazingly
well
written
piece
of
software
its
because
beautiful
soup
doesnt
include
any
parsing
code
instead
it
relies
on
external
parsers
if
one
parser
isnt
working
on
a
certain
document
the
best
solution
is
to
try
a
different
parser
see
installing
a
parser
for
details
and
a
parser
comparison
the
most
common
parse
errors
are
htmlparserhtmlparseerror
malformed
start
tag
and
htmlparserhtmlparseerror
bad
end
tag
these
are
both
generated
by
pythons
built
in
html
parser
library
and
the
solution
is
to
install
lxml
or
htmllib
the
most
common
type
of
unexpected
behavior
is
that
you
cant
find
a
tag
that
you
know
is
in
the
document
you
saw
it
going
in
but
findall
returns
or
find
returns
none
this
is
another
common
problem
with
pythons
built
in
html
parser
which
sometimes
skips
tags
it
doesnt
understand
again
the
solution
is
to
install
lxml
or
htmllib
version
mismatch
problems
parsing
xml
by
default
beautiful
soup
parses
documents
as
html
to
parse
a
document
as
xml
pass
in
xml
as
the
second
argument
to
the
beautifulsoup
constructor
youll
need
to
have
lxml
installed
other
parser
problems
miscellaneous
improving
performance
beautiful
soup
will
never
be
as
fast
as
the
parsers
it
sits
on
top
of
if
response
time
is
critical
if
youre
paying
for
computer
time
by
the
hour
or
if
theres
any
other
reason
why
computer
time
is
more
valuable
than
programmer
time
you
should
forget
about
beautiful
soup
and
work
directly
atop
lxml
that
said
there
are
things
you
can
do
to
speed
up
beautiful
soup
if
youre
not
using
lxml
as
the
underlying
parser
my
advice
is
to
start
beautiful
soup
parses
documents
significantly
faster
using
lxml
than
using
htmlparser
or
htmllib
you
can
speed
up
encoding
detection
significantly
by
installing
the
cchardet
library
parsing
only
part
of
a
document
wont
save
you
much
time
parsing
the
document
but
it
can
save
a
lot
of
memory
and
itll
make
searching
the
document
much
faster
beautiful
soup
beautiful
soup
is
the
previous
release
series
and
is
no
longer
being
actively
developed
its
currently
packaged
with
all
major
linux
distributions
apt
get
install
python
beautifulsoup
its
also
published
through
pypi
as
beautifulsoup
easyinstall
beautifulsoup
pip
install
beautifulsoup
you
can
also
download
a
tarball
of
beautiful
soup
if
you
ran
easyinstall
beautifulsoup
or
easyinstall
beautifulsoup
but
your
code
doesnt
work
you
installed
beautiful
soup
by
mistake
you
need
to
run
easyinstall
beautifulsoup
the
documentation
for
beautiful
soup
is
archived
online
porting
code
to
bs
most
code
written
against
beautiful
soup
will
work
against
beautiful
soup
with
one
simple
change
all
you
should
have
to
do
is
change
the
package
name
from
beautifulsoup
to
bs
so
this
becomes
this
although
bs
is
mostly
backwards
compatible
with
bs
most
of
its
methods
have
been
deprecated
and
given
new
names
for
pep
compliance
there
are
numerous
other
renames
and
changes
and
a
few
of
them
break
backwards
compatibility
heres
what
youll
need
to
know
to
convert
your
bs
code
and
habits
to
bs
you
need
a
parser
beautiful
soup
used
pythons
sgmlparser
a
module
that
was
deprecated
and
removed
in
python
beautiful
soup
uses
htmlparser
by
default
but
you
can
plug
in
lxml
or
htmllib
and
use
that
instead
see
installing
a
parser
for
a
comparison
since
htmlparser
is
not
the
same
parser
as
sgmlparser
you
may
find
that
beautiful
soup
gives
you
a
different
parse
tree
than
beautiful
soup
for
the
same
markup
if
you
swap
out
htmlparser
for
lxml
or
htmllib
you
may
find
that
the
parse
tree
changes
yet
again
if
this
happens
youll
need
to
update
your
scraping
code
to
deal
with
the
new
tree
method
names
some
arguments
to
the
beautiful
soup
constructor
were
renamed
for
the
same
reasons
i
renamed
one
method
for
compatibility
with
python
i
renamed
one
attribute
to
use
more
accurate
terminology
i
renamed
three
attributes
to
avoid
using
words
that
have
special
meaning
to
python
unlike
the
others
these
changes
are
not
backwards
compatible
if
you
used
these
attributes
in
bs
your
code
will
break
on
bs
until
you
change
them
generators
i
gave
the
generators
pep
compliant
names
and
transformed
them
into
properties
so
instead
of
this
you
can
write
this
but
the
old
code
will
still
work
some
of
the
generators
used
to
yield
none
after
they
were
done
and
then
stop
that
was
a
bug
now
the
generators
just
stop
there
are
two
new
generators
strings
and
strippedstrings
strings
yields
navigablestring
objects
and
strippedstrings
yields
python
strings
that
have
had
whitespace
stripped
xml
there
is
no
longer
a
beautifulstonesoup
class
for
parsing
xml
to
parse
xml
you
pass
in
xml
as
the
second
argument
to
the
beautifulsoup
constructor
for
the
same
reason
the
beautifulsoup
constructor
no
longer
recognizes
the
ishtml
argument
beautiful
soups
handling
of
empty
element
xml
tags
has
been
improved
previously
when
you
parsed
xml
you
had
to
explicitly
say
which
tags
were
considered
empty
element
tags
the
selfclosingtags
argument
to
the
constructor
is
no
longer
recognized
instead
beautiful
soup
considers
any
empty
tag
to
be
an
empty
element
tag
if
you
add
a
child
to
an
empty
element
tag
it
stops
being
an
empty
element
tag
entities
an
incoming
html
or
xml
entity
is
always
converted
into
the
corresponding
unicode
character
beautiful
soup
had
a
number
of
overlapping
ways
of
dealing
with
entities
which
have
been
removed
the
beautifulsoup
constructor
no
longer
recognizes
the
smartquotesto
or
convertentities
arguments
unicode
dammit
still
has
smartquotesto
but
its
default
is
now
to
turn
smart
quotes
into
unicode
the
constants
htmlentities
xmlentities
and
xhtmlentities
have
been
removed
since
they
configure
a
feature
transforming
some
but
not
all
entities
into
unicode
characters
that
no
longer
exists
if
you
want
to
turn
unicode
characters
back
into
html
entities
on
output
rather
than
turning
them
into
utf
characters
you
need
to
use
an
output
formatter
miscellaneous
tagstring
now
operates
recursively
if
tag
a
contains
a
single
tag
b
and
nothing
else
then
astring
is
the
same
as
bstring
previously
it
was
none
multi
valued
attributes
like
class
have
lists
of
strings
as
their
values
not
strings
this
may
affect
the
way
you
search
by
css
class
if
you
pass
one
of
the
find
methods
both
string
and
a
tag
specific
argument
like
name
beautiful
soup
will
search
for
tags
that
match
your
tag
specific
criteria
and
whose
tagstring
matches
your
value
for
string
it
will
not
find
the
strings
themselves
previously
beautiful
soup
ignored
the
tag
specific
arguments
and
looked
for
strings
the
beautifulsoup
constructor
no
longer
recognizes
the
markupmassage
argument
its
now
the
parsers
responsibility
to
handle
markup
correctly
the
rarely
used
alternate
parser
classes
like
icantbelieveitsbeautifulsoup
and
beautifulsoap
have
been
removed
its
now
the
parsers
decision
how
to
handle
ambiguous
markup
the
prettify
method
now
returns
a
unicode
string
not
a
bytestring
table
of
contents
this
page
quick
search
enter
search
terms
or
a
module
class
or
function
name
navigation
